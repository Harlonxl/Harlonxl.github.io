<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="海量数据类处理问题，是面试中非常高频的一类问题，本文归纳总结了面试中常用的海量数据处理算法。主要有以下内容：  最高频问题 布隆过滤器 外排序算法 概率类的大数据问题">
<meta property="og:type" content="article">
<meta property="og:title" content="海量数据处理算法">
<meta property="og:url" content="http://harlon.org/2018/06/23/datastructurebigdata/index.html">
<meta property="og:site_name" content="Harlon&#39;s BLOG">
<meta property="og:description" content="海量数据类处理问题，是面试中非常高频的一类问题，本文归纳总结了面试中常用的海量数据处理算法。主要有以下内容：  最高频问题 布隆过滤器 外排序算法 概率类的大数据问题">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2018-08-06T12:39:01.470Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="海量数据处理算法">
<meta name="twitter:description" content="海量数据类处理问题，是面试中非常高频的一类问题，本文归纳总结了面试中常用的海量数据处理算法。主要有以下内容：  最高频问题 布隆过滤器 外排序算法 概率类的大数据问题">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://harlon.org/2018/06/23/datastructurebigdata/"/>





  <title>海量数据处理算法 | Harlon's BLOG</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Harlon's BLOG</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Startseite
          </a>
        </li>
      
        
        <li class="menu-item menu-item-technology">
          <a href="/categories/Technology/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Technology
          </a>
        </li>
      
        
        <li class="menu-item menu-item-notes">
          <a href="/categories/Notes" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Notes
          </a>
        </li>
      
        
        <li class="menu-item menu-item-system-design">
          <a href="/categories/Design" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-bookmark"></i> <br />
            
            System Design
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://harlon.org/2018/06/23/datastructurebigdata/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Harlon">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Harlon's BLOG">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">海量数据处理算法</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-06-23T12:47:23+08:00">
                2018-06-23
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Notes/" itemprop="url" rel="index">
                    <span itemprop="name">Notes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>海量数据类处理问题，是面试中非常高频的一类问题，本文归纳总结了面试中常用的海量数据处理算法。主要有以下内容：</p>
<ul>
<li>最高频问题</li>
<li>布隆过滤器</li>
<li>外排序算法</li>
<li>概率类的大数据问题</li>
</ul>
<a id="more"></a>
<h1 id="海量数据处理问题的考点"><a href="#海量数据处理问题的考点" class="headerlink" title="海量数据处理问题的考点"></a>海量数据处理问题的考点</h1><p>首先来看一道简单的例子：<a href="https://www.lintcode.com/problem/intersection-of-two-arrays/description" target="_blank" rel="external">求数组A和数据B的交集</a><br>三种不同的解法：<br>方法一：暴力求解，对于数据B中的每一个元素，在A中查找是否存在，如果存在，添加到结果集中，注意去重（排序或hash），时间复杂度 <code>O(m*n)</code>。<br>方法二：Hash，将A中每个元素添加到hash中，遍历B中的元素，如果命中，添加到结果集中，注意去重（hash），时间复杂度<code>O(m + n)</code>。<br>方法三：二分，对A进行排序，遍历B，在A中二分查找元素是否存在，如果存在，添加到结果集中，注意去重（排序），时间复杂度<code>O(mlog(m) + nlog(n))</code>。</p>
<p>海量数据处理的问题：求两个超大文件中 URLs 的交集，内存不足以放下所有 URLs。<br>首先我们来看一下常见的考点：<br>算法方面：</p>
<ol>
<li>外排序算法（External Sorting）</li>
<li>Map Reduce</li>
<li>非精确算法</li>
<li>概率算法</li>
<li>哈希算法与哈希函数（Hash Function）</li>
</ol>
<p>数据结构方面：</p>
<ol>
<li>哈希表（Hash Table）</li>
<li>堆（Heap）</li>
<li>布隆过滤器（BloomFliter）</li>
<li>位图（Bitmap）</li>
<li>Trie树（Trie）</li>
</ol>
<hr>
<h1 id="最高频K项问题"><a href="#最高频K项问题" class="headerlink" title="最高频K项问题"></a>最高频K项问题</h1><p>问题：找到一个大文件或者数据流中出现频率最高的 K 项<br>这个问题的难点在于，如果条件不同，解决的方法是完全不一样的：</p>
<ol>
<li>是否需要精确的Top K结果？即，是否允许小概率出错。</li>
<li>数据是离线的还是在线的？即是一个大文件的形式计算一次得到一个结果，还是数据流的形式返回结果。</li>
</ol>
<hr>
<h2 id="整数数组前k大"><a href="#整数数组前k大" class="headerlink" title="整数数组前k大"></a>整数数组前k大</h2><p>问题：在一个整数数组中，找最大的 K 个整数</p>
<ol>
<li>离线算法：QuickSelect，时间复杂度<code>O(N)</code></li>
<li>在线算法：Heap，小顶堆，时间复杂度<code>O(Nlogk)</code></li>
</ol>
<hr>
<h2 id="最高频-K-项的离线算法"><a href="#最高频-K-项的离线算法" class="headerlink" title="最高频 K 项的离线算法"></a>最高频 K 项的离线算法</h2><p>伪代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 1. 用一个Hash表统计单词出现的次数</span></div><div class="line"><span class="comment"># 2. 循环每一个出现的项，用最大K项的方法，获得最大的K项</span></div><div class="line">hash = &#123;&#125;</div><div class="line"><span class="keyword">for</span> e <span class="keyword">in</span> elements:</div><div class="line">    hash[e] = hash.get(e, <span class="number">0</span>) + <span class="number">1</span></div><div class="line">    </div><div class="line"><span class="keyword">for</span> element, frequency <span class="keyword">in</span> hash:</div><div class="line">    用最小堆统计&lt;element, frequency&gt;的前K项</div></pre></td></tr></table></figure></p>
<p>问：时空复杂度：<br>答：第一步的时间复杂度<code>O(N)</code>，空间复杂度<code>O(N)</code>，第二步时间复杂度<code>O(NlogK)</code>，空间复杂度<code>O(K)</code>，总的时间复杂度<code>O(NlogK)</code>，空间复杂度<code>O(N)</code>。</p>
<p>Follow up 1：还有办法提速吗？<br>如果是上T的数据，扫描一次会非常的耗时，算法时间复杂度<code>O(NlogK)</code>看起来是理论上的下限，但有没有办法再提速？<br>问题描述：这里假设你有若干个小文件（如果是一个很大的文件，可以先进行 split，分割为若干个小文件），他们加起来有 1T 那么大。每个文件中用空格隔开若干单词，你需要统计出现次数最多的 K 个单词。</p>
<p>Map Reduce解决最高频K项问题：</p>
<ol>
<li>通过Map步骤，将每个文件中的单词一个一个取出，组成<key, 1="">这样的key-value二元组，作为Map的输出；</key,></li>
<li>通过Reduce步骤，每个Reducer将收到的key的value加起来，这样就得到了每个key出现的次数，每个Reducer维护一个小顶堆，如果大于小顶堆的堆顶，就删除堆顶元素，将元素插入堆。通过Reducer处理完成之后，输出得到的Top K；</li>
<li>可能有多个Reducer，因此我们会得到多个Top K，之后扫描这些Top K，得到最终的Top K。</li>
</ol>
<p>Follow up 2：内存不够怎么办？<br>问题描述：上面这个算法中，我们花费了 O(N) 的空间耗费，也就是需要把所有的，比如说单词，都放到内存里。<br>在现实场景中，这很可能是不行的，因为 N 可能非常的大。即便我们使用上了 Follow up 1 中的 Map Reduce 的办法，那么比如说就算你用了很多台机器，但是分到每台机器上的时候，仍然无法全部加载到内存中，也是有可能的。<br>假设现在只有一台机器，内存为 1G，你有一个 1T 大小的文件，需要统计里面最高频的 K 个单词。</p>
<hr>
<h2 id="最高频K项的在线算法"><a href="#最高频K项的在线算法" class="headerlink" title="最高频K项的在线算法"></a>最高频K项的在线算法</h2><p>问题描述：数据流中不断流过一些单词，提供一个接口，返回当前出现过的单词中，频次最高的Top K个单词。<br>即：给定的K，比如100，实现两个接口：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">add(word)</div><div class="line"><span class="comment"># 添加一个单词</span></div><div class="line"></div><div class="line">topk()</div><div class="line"><span class="comment"># 返回集合中的Top K的高频词</span></div></pre></td></tr></table></figure></p>
<p>标准在线算法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">TopKAnalyzer</span>:</span></div><div class="line">    <span class="comment"># 构造函数，初始化一个top k分析器，指定k的大小</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, k)</span>:</span></div><div class="line">        self.k = k</div><div class="line">        <span class="comment"># 初始化一个哈希堆（HashHeap）</span></div><div class="line">        self.hashheap = HashHeap()</div><div class="line"></div><div class="line">        <span class="comment"># 初始化一个哈希表，用于单词计数</span></div><div class="line">        self.hash = Hash()</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(word)</span>:</span></div><div class="line">        <span class="comment"># 单词计数 +1</span></div><div class="line">        self.hash[word] += <span class="number">1</span></div><div class="line"></div><div class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> self.hashheap:</div><div class="line">            <span class="comment"># 调整word在hashheap中的位置</span></div><div class="line">            self.hashheap.adjust(word, self.hash[word])</div><div class="line">            reutrn</div><div class="line">        </div><div class="line">        <span class="comment"># 如果没满，就接着往hashheap里面放</span></div><div class="line">        <span class="keyword">if</span> self.hashheap.size() &lt; self.k</div><div class="line">            self.hashheap.push(word, self.hash[word])</div><div class="line">        </div><div class="line">        <span class="comment"># 和hash heap里出现频次最低的单词相比</span></div><div class="line">        <span class="comment"># 如果当前单词更大，就踢掉hashheap里频次最低的单词</span></div><div class="line">        <span class="keyword">if</span> self.hash[word] &gt; self.hashheap.top().value:</div><div class="line">            self.hashheap.pop()</div><div class="line">            self.hashheap.push(word, self.hash[word])</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">topk</span><span class="params">()</span>:</span></div><div class="line">        <span class="comment"># 从hashheap中导出Top K的单词</span></div><div class="line">        <span class="keyword">return</span> self.hashheap.toList()</div></pre></td></tr></table></figure></p>
<p>复杂度分析：<br>这算法的时间复杂度要从两个维度讨论：</p>
<ol>
<li>add的时间复杂度是<code>O(logK)</code>，因此最坏情况下，就是pop掉一个单词，push进去一个新单词。由于hashheap的大小最多是k，那么复杂度为<code>O(logK)</code>。</li>
<li>topk的时间复杂度是<code>O(KlogK)</code></li>
</ol>
<p>Follow up：内存不够怎么办？<br>在上述标准的在线算法中，哈希表的耗费是最多的，如果内存无法存的下哈希表，该如何解决？<br>有哪些算法可以用精度换空间？<br>有很多科研学者都研究过这个问题，一些比较成熟的算法有：</p>
<ol>
<li>Lossy Counting</li>
<li>Sticky Sample</li>
<li>Space Saving</li>
<li>Efficent Count</li>
<li>Hash Count</li>
</ol>
<p>这里介绍一个比较容易掌握的，和标准在线算法相比之需要很少改动的一个算法：<code>Hash Count</code>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">TopKAnalyzer</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, k)</span>:</span></div><div class="line">        self.k = k</div><div class="line">        self.hashheap = HashHeap()</div><div class="line">        self.hashcount = 开一个整数数组，内存能让你开多大就开多大</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(self, word)</span>:</span></div><div class="line">        index = hashfunc(word) % self.hashcount.size</div><div class="line">        self.hashcount[index] += <span class="number">1</span></div><div class="line">        wordCount = self.hashcount[index]</div><div class="line"></div><div class="line">        <span class="comment"># 其他部分和标准在线算法一样</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">topk</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="comment"># 和标准在线算法一样</span></div></pre></td></tr></table></figure></p>
<p>上述的算法对精度的影响有多大呢？事实上，根据“长尾效应”，在实际数据的统计中，由于Top K的K相对整个数据流集合中的不同数据项个数N的关系是K远远小于N，而TopK的这些数据项的计数远远大于其他的数据项。因此，Top K的hashcode % hashcount.size扎堆的可能性是非常非常小的，因此这个算法的精确度也就不会太差。</p>
<hr>
<h1 id="布隆过滤器（Bloom-Filter"><a href="#布隆过滤器（Bloom-Filter" class="headerlink" title="布隆过滤器（Bloom Filter)"></a>布隆过滤器（Bloom Filter)</h1><h2 id="标准布隆过滤器"><a href="#标准布隆过滤器" class="headerlink" title="标准布隆过滤器"></a>标准布隆过滤器</h2><p>标准布隆过滤器的作用相当于一个 HashSet，即提供了这样一个数据结构，他支持如下操作：</p>
<ol>
<li>在集合中加入一个元素</li>
<li>判断一个元素是否在集合中（允许 False Positive）</li>
</ol>
<p><strong>实现步骤</strong></p>
<ol>
<li>初始化：开一个足够大的 boolean 数组，初始值都是 false。</li>
<li>插入一个元素：通过 k 个哈希函数，计算出元素的 k 个哈希值，对 boolean 数组的长度取模之后，标记对应的 k 个位置上的值为 true。</li>
<li>查询一个元素：通过同样的 k 哈希函数，在 boolean 数组中取出对应的 k 个位置上的值。如果都是 true，则表示该元素可能存在，如果有一个 false，则表示一定不存在。<br>伪代码：<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">StandardBloomFilter</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, capacity, hash_functions)</span>:</span></div><div class="line">        <span class="comment"># capacity is the initial size of the SBF</span></div><div class="line">        <span class="comment"># it should be as big as possible to contains all</span></div><div class="line">        <span class="comment"># of the keys</span></div><div class="line">        self.capacity = capacity</div><div class="line">        self.bitset = [<span class="keyword">False</span>] * capacity </div><div class="line">        </div><div class="line">        <span class="comment"># k hash functions</span></div><div class="line">        self.hash_functions = hash_functions</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(self, key)</span>:</span></div><div class="line">        <span class="keyword">for</span> func <span class="keyword">in</span> self.hash_functions:</div><div class="line">            position = func(key) % self.capacity</div><div class="line">            self.bitset[position] = <span class="keyword">True</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">contains</span><span class="params">(self, key)</span>:</span></div><div class="line">        <span class="keyword">for</span> func <span class="keyword">in</span> self.hash_functions:</div><div class="line">            position = func(key) % self.capacity</div><div class="line">            <span class="keyword">if</span> self.bitset[position] <span class="keyword">is</span> <span class="keyword">False</span>:</div><div class="line">                <span class="keyword">return</span> <span class="keyword">False</span></div><div class="line">                </div><div class="line">        <span class="keyword">return</span> <span class="keyword">True</span></div></pre></td></tr></table></figure>
</li>
</ol>
<p><strong>Q &amp; A</strong><br><strong>Q: 如果空间不够了怎么办呢？一开始开的 boolean 数组不够的话，如果全部都被赋为 true 了，contains 不就每次都返回 true 了么？</strong><br>A: 实际运用中，我们通常需要进行预估，也就是估算一下大概需要用到多少的空间，开多大比较合适。另外一个解决办法，是采用 Extended Bloom Filter。具体的解决方案是，当一个 BloomFilter 满了的时候，开一个新的，capacity 更大的（两倍） BloomFilter。原来的 Bloom Filter 依旧保留，这样插入的时候，总是插入到新的 BloomFilter 里，而查询的时候，所有的 BloomFilter 都要查一遍。</p>
<p><strong>Q: 如何定义一个 BloomFilter 是不是满了？</strong><br>A: 如果哈希函数用4个的话，boolean 数组的大小和实际能够存储的元素个数之间的比例，在 40: 1 比较合适。这是一个经验值。</p>
<hr>
<h2 id="计数布隆过滤器"><a href="#计数布隆过滤器" class="headerlink" title="计数布隆过滤器"></a>计数布隆过滤器</h2><p>基于标准的 BloomFilter 稍加改动，把存储所用的 boolean 数组改为 int 数组，就成为了可以计数的 BloomFilter -&gt; Counting Bloom Filter（简写为CBF）。这种数据结构类似 Java 中的 HashMap，但只能用作计数。提供如下的几种操作：</p>
<ol>
<li>O(1)时间内，在集合中加入一个元素</li>
<li>O(1)时间内，统计某个元素在该集合中出现的次数 - 但是可能会比实际出现次数要大一些<br><strong>实现步骤</strong></li>
<li>初始化：开一个足够大的 int 数组，初始值都是 0。</li>
<li>插入一个元素：通过 k 个哈希函数，计算出元素的 k 个哈希值，对 int 数组的长度取模之后，将对应的 k 个位置上的值都加一。</li>
<li>查询一个元素的出现次数：通过同样的 k 哈希函数，在 int 数组中取出对应的 k 个位置上的值。并取其中的最小值来作为该元素的出现次数预估。<br>伪代码：<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">CountingBloomFilter</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, capacity, hash_functions)</span>:</span></div><div class="line">        <span class="comment"># capacity is the initial size of the SBF</span></div><div class="line">        <span class="comment"># it should be as big as possible to contains all</span></div><div class="line">        <span class="comment"># of the keys</span></div><div class="line">        self.capacity = capacity</div><div class="line">        self.bitset = [<span class="number">0</span>] * capacity </div><div class="line">        </div><div class="line">        <span class="comment"># k hash functions</span></div><div class="line">        self.hash_functions = hash_functions</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(self, key)</span>:</span></div><div class="line">        <span class="keyword">for</span> func <span class="keyword">in</span> self.hash_functions:</div><div class="line">            position = func(key) % self.capacity</div><div class="line">            self.bitset[position] += <span class="number">1</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">contains</span><span class="params">(self, key)</span>:</span></div><div class="line">        count = sys.maxint</div><div class="line">        <span class="keyword">for</span> func <span class="keyword">in</span> self.hash_functions:</div><div class="line">            position = func(key) % self.capacity</div><div class="line">            count = min(count, self.bitset[position])</div><div class="line">                </div><div class="line">        <span class="keyword">return</span> count</div></pre></td></tr></table></figure>
</li>
</ol>
<p><strong>Q &amp; A</strong><br><strong>Q: 为什么要取最小值？</strong><br>A: 比如我们使用两个哈希函数，key1 算出来的两个下标是 0, 1, key2 算出来的 两个下标是 1, 2。这里 counts[1] 会等于 2，他被 2个 key 都影响到了。所以取最小值，能够让这个计数尽可能的毕竟真实计数。</p>
<p><strong>Q: 为什么说是预估的出现次数？而不是精确的出现次数？</strong><br>A: 承接上面问题的解答，如果还有一个 key3 算出来的下标是 0 和 2。那么 counts[0~2] 都会是 2，无论对 key1~3 的任何一个 key 取计数，都得到的是 2，要比实际的出现次数大。</p>
<p><strong>Q: CBF算出来的计数，有可能比实际出现次数小么？</strong><br>A: 不可能</p>
<hr>
<h1 id="外排序算法"><a href="#外排序算法" class="headerlink" title="外排序算法"></a>外排序算法</h1><p>外排序算法分为两个基本步骤：</p>
<ol>
<li>将大文件切分为若干个个小文件，并分别使用内存排好序</li>
<li>使用K路归并算法将若干个排好序的小文件合并到一个大文件中<br><strong>第一步：文件拆分</strong><br>根据内存的大小，尽可能多的分批次的将数据 Load 到内存中，并使用系统自带的内存排序函数（或者自己写个快速排序算法），将其排好序，并输出到一个个小文件中。比如一个文件有1T，内存有1G，那么我们就这个大文件中的内容按照 1G 的大小，分批次的导入内存，排序之后输出得到 1024 个 1G 的小文件。<br><strong>第二步：K路归并算法</strong><br>我们将 K 个文件中的第一个元素加入到堆里，假设数据是从小到大排序的话，那么这个堆是一个最小堆（Min Heap）。每次从堆中选出最小的元素，输出到目标结果文件中，然后如果这个元素来自第 x 个文件，则从第 x 个文件中继续读入一个新的数进来放到堆里，并重复上述操作，直到所有元素都被输出到目标结果文件中。<br><strong>Follow up: 一个个从文件中读入数据，一个个输出到目标文件中操作很慢，如何优化？</strong><br>如果我们每个文件只读入1个元素并放入堆里的话，总共只用到了 1024 个元素，这很小，没有充分的利用好内存。另外，单个读入和单个输出的方式也不是磁盘的高效使用方式。因此我们可以为输入和输出都分别加入一个缓冲（Buffer）。假如一个元素有10个字节大小的话，1024 个元素一共 10K，1G的内存可以支持约 100K 组这样的数据，那么我们就为每个文件设置一个 100K 大小的 Buffer，每次需要从某个文件中读数据，都将这个 Buffer 装满。当然 Buffer 中的数据都用完的时候，再批量的从文件中读入。输出同理，设置一个 Buffer 来避免单个输出带来的效率缓慢。</li>
</ol>
<hr>
<p><strong>问题描述</strong><br>给定A、B两个文件，各存放50亿个URLs，每个 URL 各占 64 字节，内存限制是 4G，让你找出A、B文件共同的 URLs？<br><strong>问题分析</strong><br>假设文件没有重复。<br><strong>方法1：文件拆分 Sharding（也可以叫 Partitioning）</strong><br>50亿，每个 URLs 64 字节，也就是每个文件 320G 的大小。很显然我们不能直接全部 Load 到内存中去处理。这种内存不够的问题，通常我们的解决方法都可以是使用 hash function 来将大文件拆分为若干个小文件。比如按照hashfunc(url) % 200进行拆分的话，可以拆分成为，200 个小文件 —— 也就是如果 hashfunc(url) % 200 = 1 就把这个 url 放到 1 号文件里。每个小文件理想状况下，大小约是 1.6 G，完全可以 Load 到内存里。<br>这种方法的好处在于，因为我们的目标是要去重，那么那些A和B中重复的 URLs，会被hashfunc(url) % 200映射到同一个文件中。这样在这个小文件中，来自 A 和 B 的 URls 在理想状况下一共 3.2G，可以全部导入内存进入重复判断筛选出有重复的 URLs。<br><strong>Q: 刚才一直在说理想情况下，那么不理想情况下是什么样的？该怎么处理？</strong><br>A: 不理想的情况下，如果 hashfunc(url) % 200 的结果比较集中，那么有可能会造成不同的 URLs 在同一个文件中扎堆的情况。这种情况下，有一些文件的大小可能会超过 4G。对于这种情况，处理的办法是进行二次拆分，把这些仍然比较大的小文件，用一个新的 hashfunc 进行拆分：hashfunc’(url) % X。这里再拆成多少个文件，可以根据文件的实际大小来定。如果二次拆分之后还是存在很大的文件，就进行三次拆分。直到每个小文件都小于 4G。</p>
<p><strong>方法2：BloomFilter</strong><br>我们可以使用一个 4G 的 Bloom Filter，它大概包含 320 亿 个 bit。把 A 文件的 50亿 个 URLs 丢入 BF 中，然后查询 B 文件的 每个 URL 是否在 BF 里。这种方法的缺点在于，320 亿个 bit 的 BF 里存 50 亿个 URLs 实在是太满了（要考虑到BF可能会用4个哈希函数），错误率会很高。因此仍然还需需要方法1中的文件拆分来分批处理。</p>
<p><strong>方法3：外排序算法</strong><br>将A,B文件分别拆分为80个小文件，每个小文件4G。每个文件在拆分的时候，每4G的数据在内存中做快速排序并将有序的URLs输出到小文件中。<br>用多路归并算法，将这160个小文件进行归并，在归并的过程中，即可知道哪些是重复的 URLs。只需将重复的 URLs 记录下来即可。</p>
<p><strong>Follow up: A,B各自有重复的 URLs</strong><br>当 A, B 各自有重复的 URLs 的时候，比如最坏情况下，A里的50亿个URLs 全部一样。B里也是。这样采用方法1这种比较容易想到的 Sharding 方法，是不奏效的，因为所有 URLs 的 hashcode 都一样，就算换不同的 hashfunc 也一样。这种情况下，需要先对两个文件进行单独的去重，方法是每 4G 的数据，放到内存中用简单的哈希表进行去重。这样，在最坏情况下，总共 320G 的数据里，一个 URLs 最多重复 8次，则不会出现太严重的扎堆情况了。算法上唯一需要稍微改动的地方是，由于 A 存在多个重复的 URLs，所以当和 B 的 URLs 被sharding 到同一个文件里的时候，需要标记一下这个 URLs 来自哪个文件，这样才能知道是否在A和B中同时出现过。</p>
<hr>
<h1 id="概率类的大数据问题"><a href="#概率类的大数据问题" class="headerlink" title="概率类的大数据问题"></a>概率类的大数据问题</h1><p><strong>面试题：等概率挑出文件中的一行</strong><br>Amazon: 一个文件中有很多行，不能全部放到内存中，如何等概率的随机挑出其中的一行？<br><strong>问题解答</strong><br>先将第一行设为候选的被选中的那一行，然后一行一行的扫描文件。假如现在是第 K 行，那么第 K 行被选中踢掉现在的候选行成为新的候选行的概率为 1/K。用一个随机函数看一下是否命中这个概率即可。命中了，就替换掉现在的候选行然后继续，没有命中就继续看下一行。</p>
<hr>
<p><strong>问题描述</strong><br>给你一个 Google 搜索日志记录，存有上亿挑搜索记录（Query）。这些搜索记录包含不同的语言。随机挑选出其中的 100 万条中文搜索记录。假设判断一条 Query 是不是中文的工具已经写好了。<br><strong>问题解答</strong><br>假设你一共要挑选 N 个 Queries，设置一个 N 的 Buffer，用于存放你选中的 Queries。对于每一条飞驰而过的<br>Query，按照如下步骤执行你的算法：<br>1.如果非中文，直接跳过<br>2.如果 Buffer 不满，将这条 Query 直接加入 Buffer 中<br>3.如果 Buffer 满了，假设当前一共出了过 M 条中文 Queries，用一个随机函数，以 N / M 的概率来决定这条 Query 是否能被选中留下。<br>3.1 如果没有选中，则跳过该 Query，继续处理下一条 Query<br>3.2 如果选中了，则用一个随机函数，以 1 / N 的概率从 Buffer 中随机挑选一个 Query 来丢掉，让当前的 Query 放进去。<br><strong>证明</strong><br>我们用 5 条 Queries 里挑 3 条来作为例子证明每条 Query 被挑中的概率都是 3/5。</p>
<ul>
<li>依次处理每条 Query，前 3 条 Queries 直接进入 Buffer =&gt; [1,2,3]，此时前 3 条 Queries 被选中的概率 100%</li>
<li>第 4 条 Query 处理时，有 3/4 的概率被留下，那么第 4 条 Query 被选中的概率此时就是 3/4。</li>
<li>第 4 条 Query 处理时，如果留下之后，会从 Buffer 中以 1/3 的概率踢走一条 Query。那么这些在 Buffer 中留下的概率是`1/4 + 2/3 * 3/4 = 3/4)。其中 1/4 是第 4 条 Query 没有被选中的概率。</li>
<li>第 5 条 Query 处理时，有 3/5 的概率被留下，那么第 5 条 Query 被选中的概率此时就是 3/5。</li>
<li>第 5 条 Query 处理时，如果留下之后，会从 Buffer 中以 1/3 的概率踢走一条 Query。前4条Query能够顺利进入Buffer并被留下的概率是：3/4 <em> (2/5 + 2/3 </em> 3/5) = 3/5。其中 2/5 是第 5 条 Query 没有被选中的概率。3/4 是前3条 Queries 在处理完第4条 Query 之后，进入 Buffer的概率，2/3 * 3/5 第5条Query被选中之后但是没有踢走自己的概率。</li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/06/20/database/" rel="next" title="深入理解MySQL底层实现">
                <i class="fa fa-chevron-left"></i> 深入理解MySQL底层实现
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/07/02/sheepdog-dog/" rel="prev" title="Sheepdog之dog源码解析">
                Sheepdog之dog源码解析 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Inhaltsverzeichnis
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Übersicht
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Harlon</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">93</span>
                  <span class="site-state-item-name">Artikel</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">Kategorien</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">Tags</span>
                
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
          </div>

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#海量数据处理问题的考点"><span class="nav-number">1.</span> <span class="nav-text">海量数据处理问题的考点</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#最高频K项问题"><span class="nav-number">2.</span> <span class="nav-text">最高频K项问题</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#整数数组前k大"><span class="nav-number">2.1.</span> <span class="nav-text">整数数组前k大</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#最高频-K-项的离线算法"><span class="nav-number">2.2.</span> <span class="nav-text">最高频 K 项的离线算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#最高频K项的在线算法"><span class="nav-number">2.3.</span> <span class="nav-text">最高频K项的在线算法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#布隆过滤器（Bloom-Filter"><span class="nav-number">3.</span> <span class="nav-text">布隆过滤器（Bloom Filter)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#标准布隆过滤器"><span class="nav-number">3.1.</span> <span class="nav-text">标准布隆过滤器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#计数布隆过滤器"><span class="nav-number">3.2.</span> <span class="nav-text">计数布隆过滤器</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#外排序算法"><span class="nav-number">4.</span> <span class="nav-text">外排序算法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#概率类的大数据问题"><span class="nav-number">5.</span> <span class="nav-text">概率类的大数据问题</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Harlon</span>

  
</div>


  <div class="powered-by">Erstellt mit  <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.3</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  





  

  

  
  

  

  

  

</body>
</html>
